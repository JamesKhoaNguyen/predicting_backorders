{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2bd855a35fb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_newdocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     __all__ = ['add_newdocs',\n\u001b[1;32m    148\u001b[0m                \u001b[0;34m'ModuleDeprecationWarning'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/add_newdocs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_newdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m###############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "training_file_path = os.path.expanduser('~/Documents/machine_learning_projects/predicting_backorders/Kaggle_Training_Dataset_v2.csv')\n",
    "testing_file_path = os.path.expanduser('~/Documents/machine_learning_projects/predicting_backorders/Kaggle_Test_Dataset_v2.csv')\n",
    "training_data = pd.read_csv(training_file_path)\n",
    "testing_data = pd.read_csv(testing_file_path)\n",
    "testing_data = testing_data.dropna()\n",
    "training_data = training_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-31c8418706a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtesting_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "training_data = training_data.replace(['Yes','No'],[1,0])\n",
    "testing_data = testing_data.replace(['Yes','No'],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = training_data.columns \n",
    "\n",
    "continuous_features = []\n",
    "column_index = 0\n",
    "continuous_features_index_tracker = []\n",
    "for column in columns:\n",
    "        #print column\n",
    "        type_value = type(training_data[column].values[0])\n",
    "        if (type_value == np.float64):\n",
    "            continuous_features.append(column)\n",
    "            continuous_features_index_tracker.append(column_index)\n",
    "        column_index += 1\n",
    "\n",
    "print continuous_features\n",
    "print len(continuous_features)\n",
    "print continuous_features_index_tracker\n",
    "print len(continuous_features_index_tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization & Feature Space Reduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#general description of continuous variables\n",
    "#display(training_data.describe())\n",
    "display(training_data.median())\n",
    "#How can the median of some of the categories be 0.00 exactly? Perhaps the medi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(training_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the mean and median of each category differs quite drastically. This indicates a need for data normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "samples = training_data.sample(100000,random_state = 36)\n",
    "#qty_related = ['national_inv', 'in_transit_qty', 'forecast_3_month', \n",
    "                   #'forecast_6_month', 'forecast_9_month', 'min_bank',\n",
    "                   #'local_bo_qty', 'pieces_past_due', 'sales_1_month', \n",
    "                   #'sales_3_month', 'sales_6_month', 'sales_9_month',]\n",
    "samples[continuous_features] = normalize(samples[continuous_features], axis=1)\n",
    "testing_data[continuous_features] = normalize(testing_data[continuous_features], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_temp = samples.drop('went_on_backorder',axis = 1).values \n",
    "y_train_temp = samples['went_on_backorder'].values\n",
    "X_test_temp = testing_data.drop('went_on_backorder', axis = 1).values\n",
    "y_test_temp = testing_data['went_on_backorder'].values\n",
    "print(X_train_temp.shape)\n",
    "print(y_train_temp.shape)\n",
    "display(X_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 12, ratio = 1.0)\n",
    "x_smote_training_data, y_smote_training_data = sm.fit_sample(X_train_temp, y_train_temp)\n",
    "print(np.bincount(y_smote_training_data))\n",
    "#display(x_smote_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#majority classifier (baseline #1)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf_dummy = DummyClassifier(strategy='most_frequent', random_state =0)\n",
    "clf_dummy.fit(x_smote_training_data, y_smote_training_data)\n",
    "clf_dummy_predictions = clf_dummy.predict(X_test_temp)\n",
    "#accuracy score\n",
    "print(clf_dummy.score(X_test_temp, y_test_temp))\n",
    "#recall score\n",
    "clf_dummy_recall = recall_score(y_test_temp,clf_dummy_predictions)\n",
    "print clf_dummy_recall\n",
    "#precision score \n",
    "clf_dummy_precision = precision_score(y_test_temp, clf_dummy_predictions)\n",
    "print clf_dummy_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#baseline #2 classifier decision tree stump\n",
    "from sklearn import tree\n",
    "clf_stump = tree.DecisionTreeClassifier(max_depth=1)\n",
    "clf_stump.fit(x_smote_training_data, y_smote_training_data)\n",
    "clf_stump_predictions = clf_stump.predict(X_test_temp)\n",
    "clf_stump_predictions_proba = clf_stump.predict_proba(X_test_temp)\n",
    "print(recall_score(y_test_temp,clf_stump_predictions))\n",
    "print(precision_score(y_test_temp, clf_stump_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Without any preprocessing, normalization, just using the out-of-the-box Random Forest Classifier\n",
    "#strange thing is that as the number of trees grow, the model's F1 score gets lower and lower\n",
    "#keep in mind that F1 score is affected by class imbalance, refer to paper\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_temp = RandomForestClassifier(n_estimators=100, max_depth = 15)\n",
    "#clf_temp = clf_temp.fit(X_train_temp, y_train_temp)\n",
    "clf_temp = clf_temp.fit(x_smote_training_data, y_smote_training_data)\n",
    "y_predict_temp = clf_temp.predict(X_test_temp)\n",
    "score_temp = metrics.f1_score(y_test_temp, y_predict_temp)\n",
    "y_predict_temp_proba = clf_temp.predict_proba(X_test_temp)\n",
    "print score_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_temp_precision_score = precision_score(y_test_temp, y_predict_temp)\n",
    "clf_temp_recall_score = recall_score(y_test_temp, y_predict_temp)\n",
    "print clf_temp_recall_score\n",
    "print clf_temp_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "#taking a look at confusion matrix for the base Random Forest Classifier without class balancing\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(y_test_temp, y_predict_temp)\n",
    "display(cm)\n",
    "sn.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "frac_of_pos, mean_pred_val = calibration_curve(y_test_temp, y_predict_temp_proba[:,1], n_bins = 10, normalize = True)\n",
    "plt.plot(mean_pred_val, frac_of_pos, color = 'blue', lw = 2, label = 'Unalibrated/Normalized/No-PCA/SMOTED RF')\n",
    "plt.plot([0,1], [0,1], color = 'navy', lw =2, linestyle = '--', label = 'Perfectly Calibrated Classifer')\n",
    "plt.xlabel('Mean Predicted Value')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve (With CV) For Normalized Data (Without PCA), SMOTED, Uncalibrated RF Classifier')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#time to do ROC curve analysis \n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "base_auc_score = roc_auc_score(y_test_temp, y_predict_temp_proba[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test_temp, y_predict_temp_proba[:,1])\n",
    "plt.plot(fpr,tpr, color='darkorange',lw=2, label = 'ROC-AUC Score = %0.2f' % base_auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label = 'Completely Random Classifier')\n",
    "plt.xlabel(\"FPR%\")\n",
    "plt.ylabel(\"TPR%\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"ROC (Without Cross-Validation) For Normalized Data (Without PCA) Without Over-Sampling or Under-Sampling, Uncalibrated Classifier\")\n",
    "plt.show()\n",
    "display(base_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculating the precision recall curve \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, threshold = precision_recall_curve(y_test_temp, y_predict_temp_proba[:,1])\n",
    "plt.plot(recall, precision, color = 'red', lw = 2)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision Recall Curve for Out of the Box Random Forest Classifier for Un-PCA-Reduced & Normalized Data\")\n",
    "plt.show()\n",
    "#from what I can tell the out of the box classifier looks like shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.cross_validation import KFold\n",
    "kfold = KFold(len(X_train_temp),n_folds = 10)\n",
    "calibrated_clf_temp = CalibratedClassifierCV(clf_temp, cv = kfold, method = 'isotonic')\n",
    "calibrated_clf_temp = calibrated_clf_temp.fit(x_smote_training_data, y_smote_training_data)\n",
    "y_predict_calibrated = calibrated_clf_temp.predict(X_test_temp)\n",
    "score_calibrated = metrics.f1_score(y_test_temp,y_predict_calibrated)\n",
    "y_predict_calibrated_proba = calibrated_clf_temp.predict_proba(X_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calibrated_clf_precision_score = precision_score(y_test_temp, y_predict_calibrated)\n",
    "calibrated_clf_recall_score = recall_score(y_test_temp, y_predict_calibrated)\n",
    "print calibrated_clf_precision_score\n",
    "print calibrated_clf_recall_score\n",
    "print y_predict_calibrated.shape\n",
    "print y_smote_training_data.shape\n",
    "print x_smote_training_data.shape\n",
    "print sum(y_smote_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(y_predict_calibrated))\n",
    "print(y_predict_calibrated_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frac_of_pos, mean_pred_val = calibration_curve(y_test_temp, y_predict_calibrated_proba[:,1], n_bins = 10, normalize = True)\n",
    "plt.plot(mean_pred_val, frac_of_pos, color = 'blue', lw = 2, label = 'Calibrated/Normalized/No-PCA/SMOTED RF')\n",
    "plt.plot([0,1], [0,1], color = 'navy', lw =2, linestyle = '--', label = 'Perfectly Calibrated Classifer')\n",
    "plt.xlabel('Mean Predicted Value')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve (With CV) For Normalized Data (Without PCA), SMOTED, Isotonically Calibrated RF Classifier')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time to do ROC curve analysis for Calibrated/KFold-Validated, SMOTED, UNPCAed classifer still using Random Forest Algorithm \n",
    "calibrated_base_auc_score = roc_auc_score(y_test_temp, y_predict_calibrated_proba[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test_temp, y_predict_calibrated_proba[:,1])\n",
    "plt.plot(fpr,tpr, color='darkorange',lw=2, label = 'ROC-AUC Score = %0.2f' % calibrated_base_auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label = 'Completely Random Classifier')\n",
    "plt.xlabel(\"FPR%\")\n",
    "plt.ylabel(\"TPR%\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"ROC(With CV) For Normalized Data (Without PCA), SMOTED, Isotonically Calibrated Classifier\")\n",
    "plt.show()\n",
    "#display(base_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_train_sample = samples['went_on_backorder'].values\n",
    "PCA_train = PCA(n_components=5)\n",
    "#X_train_reduced = PCA_train.fit_transform(X_train_temp)\n",
    "X_train_reduced = PCA_train.fit_transform(x_smote_training_data)\n",
    "clf_PCA_only = RandomForestClassifier(n_estimators=100)\n",
    "#clf_PCA_only = clf_PCA_only.fit(X_train_reduced, y_train_sample)\n",
    "clf_PCA_only = clf_PCA_only.fit(X_train_reduced, y_smote_training_data)\n",
    "X_dataset_test = testing_data.drop('went_on_backorder', axis=1).values\n",
    "y_dataset_test = testing_data['went_on_backorder'].values\n",
    "X_dataset_test_reduced = PCA_train.fit_transform(X_dataset_test)\n",
    "y_dataset_test_predictions = clf_PCA_only.predict_proba(X_dataset_test_reduced)\n",
    "#test_score = metrics.f1_score(y_dataset_test, y_dataset_test_predictions)\n",
    "#print test_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(x_smote_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time to do ROC curve analysis \n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "base_auc_score = roc_auc_score(y_dataset_test, y_dataset_test_predictions[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_dataset_test, y_dataset_test_predictions[:,1])\n",
    "plt.plot(fpr,tpr, color='darkorange',lw=2, label = 'ROC-AUC Score = %0.2f' % base_auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label = 'Completely Random Classifier')\n",
    "plt.xlabel(\"FPR%\")\n",
    "plt.ylabel(\"TPR%\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"ROC (Without Cross-Validation) For Normalized Data (Without PCA) Without Over-Sampling or Under-Sampling, Uncalibrated Classifier\")\n",
    "plt.show()\n",
    "display(base_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_dataset_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-efd1ab29467f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#calculating the precision recall curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dataset_test_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_dataset_test' is not defined"
     ]
    }
   ],
   "source": [
    "#calculating the precision recall curve \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, threshold = precision_recall_curve(y_dataset_test, y_dataset_test_predictions[:,1])\n",
    "plt.plot(recall, precision, color = 'red', lw = 2)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision Recall Curve for Out of the Box Random Forest Classifier for Un-PCA-Reduced & Normalized Data\")\n",
    "plt.show()\n",
    "\n",
    "#from what I can tell the out of the box classifier looks like shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin,TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "x = [0,1]\n",
    "y = [0]\n",
    "class custom_PCA1(BaseEstimator,ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, demo_param='demo'):\n",
    "        self.demo_param = demo_param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        closest = np.argmin(euclidean_distances(X, self.X_), axis=1)\n",
    "        return self.y_[closest]\n",
    "#custom_pca = custom_PCA1()\n",
    "#custom_dot = custom_pca.fit(X_train_temp,y_train_temp)\n",
    "#print custom_dot\n",
    "print(check_estimator(custom_PCA1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9a15f0c4081d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_joined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_PCA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/estimator_checks.pyc\u001b[0m in \u001b[0;36mcheck_estimator\u001b[0;34m(Estimator)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_all_checks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSkipTest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;31m# the only SkipTest thrown currently results from not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/testing.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/estimator_checks.pyc\u001b[0m in \u001b[0;36mcheck_estimators_dtypes\u001b[0;34m(name, estimator_orig)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mset_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9a15f0c4081d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_original, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mX_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous_feature_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mX_cont_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_cont_only'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mX_non_cont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_non_cont'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9a15f0c4081d>\u001b[0m in \u001b[0;36mcontinuous_feature_extract\u001b[0;34m(self, X_original)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcontinuous_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mall_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mX_cont_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX_non_cont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "class custom_PCA(BaseEstimator,TransformerMixin):\n",
    "    import pandas as pd \n",
    "    \n",
    "    def __init__(self,n_components = None,continuous_features = None,all_features = None):\n",
    "        self.n_components = n_components\n",
    "        self.continuous_features = continuous_features\n",
    "        self.all_features = all_features\n",
    "        self.pca = PCA(n_components = self.n_components)        \n",
    "        \n",
    "    \n",
    "    def continuous_feature_extract(self, X_original):\n",
    "        X_dict = {}\n",
    "        continuous_features = self.continuous_features\n",
    "        all_features = self.all_features \n",
    "        X_original = pd.DataFrame(X_original, columns = all_features[0:(len(all_features)-1)])\n",
    "        X_cont_only = X_original[continuous_features]\n",
    "        X_non_cont = X_original.drop(continuous_features, axis =1)\n",
    "        X_dict['X_non_cont'] = X_non_cont\n",
    "        X_dict['X_cont_only'] = X_cont_only\n",
    "        return X_dict\n",
    "        \n",
    "    \n",
    "    def fit(self,X_original, y = None):\n",
    "        X_dict = self.continuous_feature_extract(X_original)\n",
    "        X_cont_only = X_dict['X_cont_only']\n",
    "        X_non_cont = X_dict['X_non_cont']\n",
    "        X_cont_only = pd.DataFrame(self.pca.fit(X_cont_only))\n",
    "        X_joined =X_cont_only.join(X_non_cont)\n",
    "        return X_joined\n",
    "        \n",
    "\n",
    "    def fit_transform(self,X_original, y = None):\n",
    "        X_dict = self.continuous_feature_extract(X_original)\n",
    "        X_cont_only = X_dict['X_cont_only']\n",
    "        X_non_cont = X_dict['X_non_cont']\n",
    "        X_cont_only = pd.DataFrame(self.pca.fit_transform(X_cont_only))\n",
    "        X_joined = X_cont_only.join(X_non_cont)\n",
    "        return X_joined\n",
    "    \n",
    "    def transform(self,X_original, y = None):\n",
    "        X_dict = self.continuous_feature_extract(X_original)\n",
    "        X_cont_only = X_dict['X_cont_only']\n",
    "        X_non_cont = X_dict['X_non_cont']\n",
    "        X_cont_only = pd.DataFrame(self.pca.transform(X_cont_only))\n",
    "        X_joined = X_cont_only.join(X_non_cont)\n",
    "        return X_joined\n",
    "\n",
    "print(check_estimator(custom_PCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DenseTransformer(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        \n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class JamesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    def __init__(self,n_components = None, **kwargs):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(self.n_components)\n",
    "    \n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        X = self.pca.transform(X)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y= None, **kwargs):\n",
    "        X = self.pca.fit_transform(X)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        X = self.pca.fit(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('reduce_dim', JamesTransformer(n_components=None)), ('classify', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_i..._jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'classify__n_estimators': [1, 8]}, {'reduce_dim__n_components': [2]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#pipeline test\n",
    "pipe = Pipeline([('reduce_dim', JamesTransformer()),('classify', RandomForestClassifier())])\n",
    "C_OPTIONS = [1,8]\n",
    "N_COMPONENTS = [2]\n",
    "param_grid = [{'classify__n_estimators': C_OPTIONS},\n",
    "              {'reduce_dim__n_components':N_COMPONENTS}\n",
    "             ]\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, n_jobs=1, param_grid=param_grid)\n",
    "digits = load_digits()\n",
    "grid.fit(digits.data, digits.target)\n",
    "print grid\n",
    "grid.predict(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('reduce_dim', PCA()),\n",
    "#     ('classify', \n",
    "# ])\n",
    "\n",
    "# N_FEATURES_OPTIONS = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,]\n",
    "# C_OPTIONS = [1, 10, 100, 1000]\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "#         'reduce_dim_n__components': N_FEATURES_OPTIONS,\n",
    "#         'classify__C': C_OPTIONS\n",
    "#     },\n",
    "#     {\n",
    "#         'reduce_dim': [SelectKBest(chi2)],\n",
    "#         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "#         'classify__C': C_OPTIONS\n",
    "#     },\n",
    "# ]\n",
    "# reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']\n",
    "\n",
    "# grid = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "# digits = load_digits()\n",
    "# grid.fit(digits.data, digits.target)\n",
    "\n",
    "x_pca_smote_train = custom_pca(x_smote_training_data,2, continuous_features)                        \n",
    "#display(x_pca_smote_train)\n",
    "x_pca_smote_test = custom_pca(X_test_temp,2,continuous_features)\n",
    "print(x_pca_smote_train.shape)\n",
    "print(x_pca_smote_test.shape)\n",
    "#display(x_pca_smote_test)\n",
    "clf_PCA_only_ = RandomForestClassifier(n_estimators=100)\n",
    "clf_PCA_only = clf_PCA_only.fit(x_pca_smote_train, y_smote_training_data)\n",
    "y_dataset_test_predictions = clf_PCA_only.predict(x_pca_smote_test)\n",
    "y_dataset_test_predictions_proba = clf_PCA_only.predict_proba(x_pca_smote_test)\n",
    "test_score = metrics.f1_score(y_dataset_test, y_dataset_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time to do ROC curve analysis \n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "base_auc_score = roc_auc_score(y_dataset_test, y_dataset_test_predictions_proba[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_dataset_test, y_dataset_test_predictions_proba[:,1])\n",
    "plt.plot(fpr,tpr, color='darkorange',lw=2, label = 'ROC-AUC Score = %0.2f' % base_auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label = 'Completely Random Classifier')\n",
    "plt.xlabel(\"FPR%\")\n",
    "plt.ylabel(\"TPR%\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"ROC (Without Cross-Validation) For Normalized Data (Without PCA) Without Over-Sampling or Under-Sampling, Uncalibrated Classifier\")\n",
    "plt.show()\n",
    "display(base_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
